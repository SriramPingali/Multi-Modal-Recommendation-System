{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f00f8a9",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d376d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"0, 1, 2, 3, 4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d734b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srirampingali/anaconda3/envs/BTP/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3f2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.loader import DataLoader, NeighborLoader, HGTLoader, NeighborLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a31d8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e88960e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu117'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf29826",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68193062",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_csv = \"../Datasets/ml-100k/Text/items.csv\"\n",
    "train_ratings = \"../Datasets/ml-100k/Text/u1.base\"\n",
    "test_ratings = \"../Datasets/ml-100k/Text/u1.test\"\n",
    "item_path = \"../Datasets/ml-100k/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06fd8195",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = 943\n",
    "n_items = 1682"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64284205",
   "metadata": {},
   "source": [
    "## Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a88987",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensDataset():\n",
    "    def __init__(self, ratings = train_ratings, item_path = item_path, device = device):\n",
    "        self.video_embeddings = pd.read_csv(item_path + \"Video/embeddings.csv\").to_numpy()\n",
    "        self.audio_embeddings = pd.read_csv(item_path + \"Audio/embeddings.csv\").to_numpy()\n",
    "        self.meta_embeddings = pd.read_csv(item_path + \"Meta/embeddings.csv\").to_numpy()\n",
    "        self.text_embeddings = pd.read_csv(item_path + \"Text/embeddings.csv\").to_numpy()\n",
    "        self.user_embeddings = pd.read_csv(item_path + \"User/embeddings.csv\").to_numpy()\n",
    "        self.ratings = pd.read_csv(ratings, sep='\\t', \n",
    "                                   names=['user_id', 'movie_id', 'rating', 'unix_timestamp'],encoding='latin-1')\n",
    "        self.indices = None\n",
    "        self.device = device\n",
    "        self.data = None\n",
    "        self.n_users = None\n",
    "        self.n_items = None\n",
    "        self.dataset = HeteroData()\n",
    "        self.fill_ratings()\n",
    "        self.embeddings()\n",
    "    \n",
    "    def fill_ratings(self, threshold=4):\n",
    "        self.n_users = self.ratings.user_id.unique().shape[0]\n",
    "        self.n_items = self.ratings.movie_id.unique().shape[0]\n",
    "        self.edge_index = []\n",
    "        self.edge_label = []\n",
    "        \n",
    "        self.data = np.zeros((n_users, n_items))\n",
    "        for line in self.ratings.itertuples():\n",
    "            if(line[3] >= 1):\n",
    "                self.data[line[1] - 1, line[2] - 1] = line[3]\n",
    "                self.edge_index.append(torch.tensor([line[1] - 1, line[2] - 1], dtype = torch.long))\n",
    "                self.edge_label.append(line[3] - 1)\n",
    "\n",
    "        self.edge_index = torch.stack(self.edge_index, 1).to(self.device)\n",
    "        self.edge_label = torch.tensor(self.edge_label, dtype = torch.long).to(self.device)\n",
    "    \n",
    "    def embeddings(self):\n",
    "        self.audio_embeddings = np.nan_to_num(self.audio_embeddings)\n",
    "        self.video_embeddings = np.nan_to_num(self.video_embeddings)\n",
    "        self.audio_embeddings = normalize(self.audio_embeddings, axis = 0)\n",
    "        \n",
    "#         self.dataset['movies'].x = torch.tensor(self.text_embeddings, dtype = torch.float).to(self.device)\n",
    "#         self.dataset['users'].x  = torch.tensor(self.user_embeddings, dtype = torch.float).to(self.device)\n",
    "        self.dataset['movies'].x = torch.tensor(self.data.T, dtype = torch.float).to(self.device)\n",
    "        self.dataset['users'].x  = torch.tensor(self.data, dtype = torch.float).to(self.device)\n",
    "        self.dataset['users', 'likes', 'movies'].edge_index = self.edge_index\n",
    "        self.dataset['users', 'likes', 'movies'].edge_label  = self.edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfe61cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MovielensDataset(ratings = train_ratings).dataset\n",
    "test_data = MovielensDataset(ratings = test_ratings).dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7da00061",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovies\u001b[0m={ x=[1682, 943] },\n",
       "  \u001b[1musers\u001b[0m={ x=[943, 1682] },\n",
       "  \u001b[1m(users, likes, movies)\u001b[0m={\n",
       "    edge_index=[2, 80000],\n",
       "    edge_label=[80000]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea00fcf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovies\u001b[0m={ x=[1682, 943] },\n",
       "  \u001b[1musers\u001b[0m={ x=[943, 1682] },\n",
       "  \u001b[1m(users, likes, movies)\u001b[0m={\n",
       "    edge_index=[2, 20000],\n",
       "    edge_label=[20000]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca0a21",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f5bd850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "import torch_geometric.utils as utils\n",
    "\n",
    "train_data  = T.ToUndirected()(train_data)\n",
    "test_data  = T.ToUndirected()(test_data)\n",
    "train_data, val_data, temp = T.RandomLinkSplit(edge_types=[('users', 'likes', 'movies')], \n",
    "                                            rev_edge_types=[('movies', 'rev_likes', 'users')],\n",
    "                                            # is_undirected = True,\n",
    "                                            num_val = 0,\n",
    "                                            num_test = 0)(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d544ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(val_data['users', 'movies'].edge_label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "857a5322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovies\u001b[0m={ x=[1682, 943] },\n",
       "  \u001b[1musers\u001b[0m={ x=[943, 1682] },\n",
       "  \u001b[1m(users, likes, movies)\u001b[0m={\n",
       "    edge_index=[2, 80000],\n",
       "    edge_label=[160000],\n",
       "    edge_label_index=[2, 160000]\n",
       "  },\n",
       "  \u001b[1m(movies, rev_likes, users)\u001b[0m={\n",
       "    edge_index=[2, 80000],\n",
       "    edge_label=[80000]\n",
       "  },\n",
       "  \u001b[1m(users, rev_rev_likes, movies)\u001b[0m={\n",
       "    edge_index=[2, 80000],\n",
       "    edge_label=[80000]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17da5487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovies\u001b[0m={ x=[1682, 943] },\n",
       "  \u001b[1musers\u001b[0m={ x=[943, 1682] },\n",
       "  \u001b[1m(users, likes, movies)\u001b[0m={\n",
       "    edge_index=[2, 80000],\n",
       "    edge_label=[0],\n",
       "    edge_label_index=[2, 0]\n",
       "  },\n",
       "  \u001b[1m(movies, rev_likes, users)\u001b[0m={\n",
       "    edge_index=[2, 80000],\n",
       "    edge_label=[80000]\n",
       "  },\n",
       "  \u001b[1m(users, rev_rev_likes, movies)\u001b[0m={\n",
       "    edge_index=[2, 80000],\n",
       "    edge_label=[80000]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f551dbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovies\u001b[0m={ x=[1682, 943] },\n",
       "  \u001b[1musers\u001b[0m={ x=[943, 1682] },\n",
       "  \u001b[1m(users, likes, movies)\u001b[0m={\n",
       "    edge_index=[2, 20000],\n",
       "    edge_label=[20000]\n",
       "  },\n",
       "  \u001b[1m(movies, rev_likes, users)\u001b[0m={\n",
       "    edge_index=[2, 20000],\n",
       "    edge_label=[20000]\n",
       "  },\n",
       "  \u001b[1m(users, rev_rev_likes, movies)\u001b[0m={\n",
       "    edge_index=[2, 20000],\n",
       "    edge_label=[20000]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dca5362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "HeteroData.get_edge_store() missing 1 required positional argument: 'dst'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124musers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovies\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39medge_label_index \u001b[38;5;241m=\u001b[39m \u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musers\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovies\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39medge_index\n",
      "File \u001b[0;32m~/anaconda3/envs/BTP/lib/python3.10/site-packages/torch_geometric/data/hetero_data.py:164\u001b[0m, in \u001b[0;36mHeteroData.__getitem__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_edge_store\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_node_store(key)\n",
      "\u001b[0;31mTypeError\u001b[0m: HeteroData.get_edge_store() missing 1 required positional argument: 'dst'"
     ]
    }
   ],
   "source": [
    "test_data['users', 'movies'].edge_label_index = test_data['users', 'movies'].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d43980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "# loader = LinkNeighborLoader(\n",
    "#     train_data,\n",
    "#     num_neighbors=[30] * 2,\n",
    "#     batch_size=128,\n",
    "#     edge_label_index=train_data['users', 'likes', 'movies'].edge_index,\n",
    "# )\n",
    "\n",
    "loader = HGTLoader(\n",
    "    train_data,\n",
    "    # Sample 512 nodes per type and per iteration for 4 iterations\n",
    "    num_samples={key: [512] * 4 for key in train_data.node_types},\n",
    "    # Use a batch size of 128 for sampling training nodes of type paper\n",
    "    batch_size=128,\n",
    "    input_nodes='movies',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd0fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b2c058",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.bincount(train_data['users', 'movies'].edge_label)\n",
    "weight = weight.max() / weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb94a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse_loss(pred, target, weight=weight):\n",
    "    target = target.long()\n",
    "    weight = weight[target].to(pred.dtype)\n",
    "    loss = (pred - target.to(pred.dtype)).pow(2)\n",
    "    return ((weight * loss).mean(), loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a555be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "import torch_geometric.nn as nng\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels = 100, out_channels = 100):\n",
    "        super().__init__()\n",
    "        self.conv1 = nng.GATConv((-1, -1), hidden_channels)#, train_data.metadata())\n",
    "        self.conv2 = nng.GATConv((-1, -1), out_channels)#, train_data.metadata())\n",
    "        self.conv3 = nng.GATConv((-1, -1), out_channels)#, train_data.metadata())\n",
    "#         self.conv1 = nng.HGTConv(-1, hidden_channels, train_data.metadata())\n",
    "#         self.conv2 = nng.HGTConv(-1, out_channels, train_data.metadata())\n",
    "#         self.conv3 = nng.HGTConv(-1, out_channels, train_data.metadata())\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = self.conv3(x, edge_index).relu()\n",
    "        return x\n",
    "    \n",
    "class SiameseDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels = 100, out_channels = 300):\n",
    "        super().__init__()\n",
    "#         self.encoder_user = nn.Sequential(OrderedDict([\n",
    "#             ('linr1', nn.Linear(hidden_channels, 256)),\n",
    "#             ('relu1', nn.Sigmoid()),\n",
    "#             ('linr2', nn.Linear(256, out_channels)),\n",
    "#             ('relu2', nn.LeakyReLU()),\n",
    "#         ]))\n",
    "        \n",
    "#         self.encoder_item = nn.Sequential(OrderedDict([\n",
    "#             ('linr1', nn.Linear(hidden_channels, 256)),\n",
    "#             ('relu1', nn.Sigmoid()),\n",
    "#             ('linr2', nn.Linear(256, out_channels)),\n",
    "#             ('relu2', nn.LeakyReLU()),\n",
    "#         ]))\n",
    "        \n",
    "        self.siamese = nn.Sequential(OrderedDict([\n",
    "            ('linr1', nn.Linear(hidden_channels, 200)),\n",
    "            ('relu1', nn.LeakyReLU()),\n",
    "            ('linr2', nn.Linear(200, 100)),\n",
    "#             ('relu2', nn.LeakyReLU()),\n",
    "#             ('linr3', nn.Linear(256, 100)),\n",
    "#             ('relu3', nn.LeakyReLU()),\n",
    "        ]))\n",
    "        \n",
    "        self.ffn = nn.Sequential(OrderedDict([\n",
    "            ('linr1', nn.Linear(2000, 164)),\n",
    "            ('actv1', nn.ReLU()),\n",
    "            ('linr2', nn.Linear(164, 1)),\n",
    "        ]))\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "#         print(z_dict['movies'][row])\n",
    "#         z_i = self.encoder_item(z_dict['movies'][row])\n",
    "        z_i = self.siamese(z_dict['movies'][row])\n",
    "#         z_u = self.encoder_user(z_dict['users'][row])\n",
    "        z_u = self.siamese(z_dict['users'][row])\n",
    "#         z = self.ffn(torch.cat((z_i, z_u), axis=1))\n",
    "        z = self.ffn(torch.cat((z_dict['users'][row], z_dict['movies'][row]), axis=1))\n",
    "        return(z_i, z_u, z)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = nng.to_hetero(self.encoder, train_data.metadata(), aggr='sum')\n",
    "        self.decoder = SiameseDecoder(hidden_channels)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x_dict, edge_index_dict, edge_label_index = data.x_dict, data.edge_index_dict, data['users', 'movies'].edge_label_index\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)\n",
    "    \n",
    "    def train(self, data = train_data, epochs = 1000):\n",
    "        self.pred_loss = weighted_mse_loss\n",
    "        self.embd_loss = nn.CosineEmbeddingLoss()\n",
    "        self.optim = torch.optim.Adam(self.parameters(), lr = 1e-4)\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        for i in tqdm(range(epochs)):\n",
    "            self.optim.zero_grad()\n",
    "            otpt = self.forward(data)\n",
    "            trgt = data['users', 'movies'].edge_label.float()\n",
    "            loss, loss_ = self.pred_loss(otpt[2], trgt)\n",
    "            loss += self.embd_loss(otpt[0], otpt[1], torch.div(trgt, 2, rounding_mode='floor') * 2 - 1)\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            self.train_loss.append(torch.sqrt(loss_).cpu().detach().numpy())\n",
    "            self.val_loss.append(self.test().cpu().detach().numpy())\n",
    "        return(self.train_loss, self.val_loss)\n",
    "            \n",
    "    def test(self, data = test_data):\n",
    "        with torch.no_grad():\n",
    "            otpt = self.forward(data)\n",
    "            trgt = data['users', 'movies'].edge_label.float()\n",
    "            _, loss = self.pred_loss(otpt[2], trgt)\n",
    "            return(torch.sqrt(loss))\n",
    "\n",
    "model = Model(hidden_channels = 1000).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332038d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = model.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd7eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "ax.plot(output[0][50:], label = \"Train Loss\", color = \"orange\")\n",
    "ax2.plot(output[1][50:], label = \"Test Loss\")\n",
    "fig.legend([ax, ax2], labels = [\"Train Loss\", \"Test Loss\"], loc = \"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c588773",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(train_data)[2].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d604ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "true = train_data['users', 'movies'].edge_label.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044652fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(pred, true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bacc37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
