{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f00f8a9",
   "metadata": {
    "id": "9f00f8a9"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d376d13",
   "metadata": {
    "id": "0d376d13"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"0, 1, 2, 3, 4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d734b3",
   "metadata": {
    "id": "f8d734b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/srirampingali/anaconda3/envs/BTP/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d3f2e9c",
   "metadata": {
    "id": "9d3f2e9c"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "from torch_geometric.loader import DataLoader, NeighborLoader, HGTLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a31d8cc",
   "metadata": {
    "id": "5a31d8cc",
    "outputId": "55d6dfa3-5a84-47c7-c9c0-c15edd741ccc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e88960e9",
   "metadata": {
    "id": "e88960e9",
    "outputId": "607a1a5c-3dcb-4f21-a18c-6931672b3dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1+cu117'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf29826",
   "metadata": {
    "id": "bdf29826"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68193062",
   "metadata": {
    "id": "68193062"
   },
   "outputs": [],
   "source": [
    "items_csv = \"../Datasets/ml-100k/Text/items.csv\"\n",
    "train_ratings = \"../Datasets/ml-100k/Text/u1.base\"\n",
    "test_ratings = \"../Datasets/ml-100k/Text/u1.test\"\n",
    "item_path = \"../Datasets/ml-100k/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06fd8195",
   "metadata": {
    "id": "06fd8195"
   },
   "outputs": [],
   "source": [
    "n_users = 943\n",
    "n_items = 1682"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64284205",
   "metadata": {
    "id": "64284205"
   },
   "source": [
    "## Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a88987",
   "metadata": {
    "id": "58a88987"
   },
   "outputs": [],
   "source": [
    "# class MovielensDataset():\n",
    "#     def __init__(self, ratings = train_ratings, item_path = item_path, device = device):\n",
    "#         self.video_embeddings = pd.read_csv(item_path + \"Video/embeddings.csv\").to_numpy()\n",
    "#         self.audio_embeddings = pd.read_csv(item_path + \"Audio/embeddings.csv\").to_numpy()\n",
    "#         self.meta_embeddings = pd.read_csv(item_path + \"Meta/embeddings.csv\").to_numpy()\n",
    "#         self.text_embeddings = pd.read_csv(item_path + \"Text/embeddings.csv\").to_numpy()\n",
    "#         self.user_embeddings = pd.read_csv(item_path + \"User/embeddings.csv\").to_numpy()\n",
    "#         self.ratings = pd.read_csv(ratings, sep='\\t', \n",
    "#                                    names=['user_id', 'movie_id', 'rating', 'unix_timestamp'],encoding='latin-1')\n",
    "#         self.indices = None\n",
    "#         self.device = device\n",
    "#         self.data = None\n",
    "#         self.n_users = None\n",
    "#         self.n_items = None\n",
    "#         self.dataset = HeteroData()\n",
    "#         self.fill_ratings()\n",
    "#         self.embeddings()\n",
    "    \n",
    "#     def fill_ratings(self, threshold=4):\n",
    "#         self.n_users = self.ratings.user_id.unique().shape[0]\n",
    "#         self.n_items = self.ratings.movie_id.unique().shape[0]\n",
    "#         self.edge_index = []\n",
    "#         self.edge_label = []\n",
    "        \n",
    "#         self.data = np.zeros((n_users, n_items))\n",
    "#         for line in self.ratings.itertuples():\n",
    "#             if(line[3] >= 1):\n",
    "#                 self.data[line[1] - 1, line[2] - 1] = line[3]\n",
    "#                 self.edge_index.append(torch.tensor([line[1] - 1, line[2] - 1], dtype = torch.long))\n",
    "#                 self.edge_label.append(line[3] - 1)\n",
    "\n",
    "#         self.edge_index = torch.stack(self.edge_index, 1).to(self.device)\n",
    "#         self.edge_label = torch.tensor(self.edge_label, dtype = torch.long).to(self.device)\n",
    "    \n",
    "#     def embeddings(self):\n",
    "#         self.audio_embeddings = np.nan_to_num(self.audio_embeddings)\n",
    "#         self.video_embeddings = np.nan_to_num(self.video_embeddings)\n",
    "#         self.audio_embeddings = normalize(self.audio_embeddings, axis = 0)\n",
    "        \n",
    "#         self.dataset['movies'].x = torch.tensor(self.audio_embeddings, dtype = torch.float).to(self.device)\n",
    "#         self.dataset['users'].x  = torch.tensor(self.user_embeddings, dtype = torch.float).to(self.device)\n",
    "#         self.dataset['users', 'likes', 'movies'].edge_index = self.edge_index\n",
    "#         self.dataset['users', 'likes', 'movies'].edge_label  = self.edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6323a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensDataset():\n",
    "    def __init__(self, ratings = train_ratings, item_path = item_path, device = device):\n",
    "        self.video_embeddings = pd.read_csv(item_path + \"Video/embeddings.csv\").to_numpy()\n",
    "        self.audio_embeddings = pd.read_csv(item_path + \"Audio/embeddings.csv\").to_numpy()\n",
    "        self.meta_embeddings = pd.read_csv(item_path + \"Meta/embeddings.csv\").to_numpy()\n",
    "        self.text_embeddings = pd.read_csv(item_path + \"Text/embeddings.csv\").to_numpy()\n",
    "        self.user_embeddings = pd.read_csv(item_path + \"User/embeddings.csv\").to_numpy()\n",
    "        self.ratings = pd.read_csv(ratings, sep='\\t', \n",
    "                                   names=['user_id', 'movie_id', 'rating', 'unix_timestamp'],encoding='latin-1')\n",
    "        self.indices = None\n",
    "        self.device = device\n",
    "        self.data = None\n",
    "        self.n_users = None\n",
    "        self.n_items = None\n",
    "        self.dataset = HeteroData()\n",
    "        self.fill_ratings()\n",
    "        self.embeddings()\n",
    "    \n",
    "    def fill_ratings(self, threshold=4):\n",
    "        self.n_users = self.ratings.user_id.unique().shape[0]\n",
    "        self.n_items = self.ratings.movie_id.unique().shape[0]\n",
    "        self.edge_index = []\n",
    "        self.edge_label = []\n",
    "        \n",
    "        self.data = np.zeros((n_users, n_items))\n",
    "        for line in self.ratings.itertuples():\n",
    "            if(line[3] >= 1):\n",
    "                self.data[line[1] - 1, line[2] - 1] = line[3]\n",
    "                self.edge_index.append(torch.tensor([line[1] - 1, line[2] - 1], dtype = torch.long))\n",
    "                self.edge_label.append(line[3] - 1)\n",
    "        \n",
    "        self.edge_index = torch.stack(self.edge_index, 1).to(self.device)\n",
    "        self.edge_label = torch.tensor(self.edge_label, dtype = torch.long).to(self.device)\n",
    "    \n",
    "    def embeddings(self):\n",
    "#         self.audio_embeddings = np.nan_to_num(self.audio_embeddings)\n",
    "#         self.video_embeddings = np.nan_to_num(self.video_embeddings)\n",
    "#         self.audio_embeddings = normalize(self.audio_embeddings, axis = 0)\n",
    "        in_ = torch.cat( (torch.tensor(self.text_embeddings, dtype = torch.float).to(self.device),\n",
    "                        torch.tensor(self.video_embeddings, dtype = torch.float).to(self.device)), axis=1)\n",
    "#         print(in_.shape)\n",
    "        self.dataset['movies'].x  = in_\n",
    "#         self.dataset['movies'].x = torch.tensor(self.meta_embeddings, dtype = torch.float).to(self.device)\n",
    "        self.dataset['users'].x  = torch.tensor(self.user_embeddings, dtype = torch.float).to(self.device)\n",
    "#         self.dataset['movies'].x = torch.tensor(self.data.T, dtype = torch.float).to(self.device)\n",
    "#         self.dataset['users'].x  = torch.tensor(self.data, dtype = torch.float).to(self.device)\n",
    "        self.dataset['users', 'likes', 'movies'].edge_index = self.edge_index\n",
    "        self.dataset['users', 'likes', 'movies'].edge_label  = self.edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfe61cb3",
   "metadata": {
    "id": "cfe61cb3"
   },
   "outputs": [],
   "source": [
    "train_data = MovielensDataset(ratings = train_ratings).dataset\n",
    "test_data = MovielensDataset(ratings = test_ratings).dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7da00061",
   "metadata": {
    "id": "7da00061",
    "outputId": "d5610b24-1493-4b38-ff95-7f97167d329f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovies\u001b[0m={ x=[1682, 1408] },\n",
       "  \u001b[1musers\u001b[0m={ x=[943, 1220] },\n",
       "  \u001b[1m(users, likes, movies)\u001b[0m={\n",
       "    edge_index=[2, 80000],\n",
       "    edge_label=[80000]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea00fcf2",
   "metadata": {
    "id": "ea00fcf2",
    "outputId": "fc8d9a92-c071-453d-c62a-5445131db68e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovies\u001b[0m={ x=[1682, 1408] },\n",
       "  \u001b[1musers\u001b[0m={ x=[943, 1220] },\n",
       "  \u001b[1m(users, likes, movies)\u001b[0m={\n",
       "    edge_index=[2, 20000],\n",
       "    edge_label=[20000]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca0a21",
   "metadata": {
    "id": "0fca0a21"
   },
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f5bd850",
   "metadata": {
    "id": "1f5bd850"
   },
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "\n",
    "train_data  = T.ToUndirected()(train_data)\n",
    "test_data  = T.ToUndirected()(test_data)\n",
    "train_data, val_data, temp = T.RandomLinkSplit(edge_types=[('users', 'likes', 'movies')], \n",
    "                                            rev_edge_types=[('movies', 'rev_likes', 'users')],\n",
    "                                            num_val = 0,\n",
    "                                            num_test = 0)(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "857a5322",
   "metadata": {
    "id": "857a5322",
    "outputId": "51adae4b-80f1-49a2-dacb-ca800d0242ae",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovies\u001b[0m={ x=[1682, 1408] },\n",
       "  \u001b[1musers\u001b[0m={ x=[943, 1220] },\n",
       "  \u001b[1m(users, likes, movies)\u001b[0m={\n",
       "    edge_index=[2, 80000],\n",
       "    edge_label=[160000],\n",
       "    edge_label_index=[2, 160000]\n",
       "  },\n",
       "  \u001b[1m(movies, rev_likes, users)\u001b[0m={\n",
       "    edge_index=[2, 80000],\n",
       "    edge_label=[80000]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17da5487",
   "metadata": {
    "id": "17da5487",
    "outputId": "f25ee3af-314a-4bbc-9704-5222f53de5cd",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovies\u001b[0m={ x=[1682, 1408] },\n",
       "  \u001b[1musers\u001b[0m={ x=[943, 1220] },\n",
       "  \u001b[1m(users, likes, movies)\u001b[0m={\n",
       "    edge_index=[2, 80000],\n",
       "    edge_label=[0],\n",
       "    edge_label_index=[2, 0]\n",
       "  },\n",
       "  \u001b[1m(movies, rev_likes, users)\u001b[0m={\n",
       "    edge_index=[2, 80000],\n",
       "    edge_label=[80000]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f551dbac",
   "metadata": {
    "id": "f551dbac",
    "outputId": "bbf05d55-d6a8-49dd-b0f6-6d616fc82e69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmovies\u001b[0m={ x=[1682, 1408] },\n",
       "  \u001b[1musers\u001b[0m={ x=[943, 1220] },\n",
       "  \u001b[1m(users, likes, movies)\u001b[0m={\n",
       "    edge_index=[2, 20000],\n",
       "    edge_label=[20000]\n",
       "  },\n",
       "  \u001b[1m(movies, rev_likes, users)\u001b[0m={\n",
       "    edge_index=[2, 20000],\n",
       "    edge_label=[20000]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dca5362",
   "metadata": {
    "id": "0dca5362",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data['users', 'movies'].edge_label_index = test_data['users', 'movies'].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84d43980",
   "metadata": {
    "id": "84d43980"
   },
   "outputs": [],
   "source": [
    "# train_loader = HGTLoader(\n",
    "#     train_data,\n",
    "#     # Sample 15 neighbors for each node and each edge type for 2 iterations:\n",
    "#     num_neighbors = [15] * 2,\n",
    "#     # Use a batch size of 128 for sampling training nodes of type \"paper\":\n",
    "#     batch_size = 10,\n",
    "#     input_nodes = torch.arange(0, n_users)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85bd0fb5",
   "metadata": {
    "id": "85bd0fb5"
   },
   "outputs": [],
   "source": [
    "# sampled_data = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac0ebdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.bincount(train_data['users', 'movies'].edge_label)\n",
    "weight = weight.max() / weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d07dc31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse_loss(pred, target, weight=weight):\n",
    "    target = target.long()\n",
    "    weight = weight[target].to(pred.dtype)\n",
    "    loss = (pred - target.to(pred.dtype)).pow(2)\n",
    "    return ((weight * loss).mean(), loss.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a555be8",
   "metadata": {
    "id": "9a555be8"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'add_self_loops' attribute set to 'True' on module 'GATConv((-1, -1), 500, heads=1)' for use with edge type(s) '[('users', 'likes', 'movies'), ('movies', 'rev_likes', 'users')]'. This will lead to incorrect message passing results.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 78\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;28mprint\u001b[39m(classification_report(trgt, otpt, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39msqrt(loss_),\n\u001b[1;32m     75\u001b[0m                precision_score(trgt, otpt, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m), \n\u001b[1;32m     76\u001b[0m                recall_score(trgt, otpt, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 78\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_channels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[23], line 41\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, hidden_channels)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m GNNEncoder(hidden_channels, hidden_channels)\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mnng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_hetero\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m EdgeDecoder(hidden_channels)\n",
      "File \u001b[0;32m~/anaconda3/envs/BTP/lib/python3.10/site-packages/torch_geometric/nn/to_hetero_transformer.py:119\u001b[0m, in \u001b[0;36mto_hetero\u001b[0;34m(module, metadata, aggr, input_map, debug)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Converts a homogeneous GNN model into its heterogeneous equivalent in\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03mwhich node representations are learned for each node type in\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m:obj:`metadata[0]`, and messages are exchanged between each edge type in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m        transformation in debug mode. (default: :obj:`False`)\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m transformer \u001b[38;5;241m=\u001b[39m ToHeteroTransformer(module, metadata, aggr, input_map, debug)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/BTP/lib/python3.10/site-packages/torch_geometric/nn/fx.py:157\u001b[0m, in \u001b[0;36mTransformer.transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m is_global_pooling_op(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, op, node\u001b[38;5;241m.\u001b[39mtarget):\n\u001b[1;32m    156\u001b[0m         op \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall_global_pooling_module\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Remove all unused nodes in the computation graph, i.e., all nodes\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# which have been replaced by node type-wise or edge type-wise variants\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# but which are still present in the computation graph.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# We do this by iterating over the computation graph in reversed order,\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# and try to remove every node. This does only succeed in case there\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# are no users of that node left in the computation graph.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnodes)):\n",
      "File \u001b[0;32m~/anaconda3/envs/BTP/lib/python3.10/site-packages/torch_geometric/nn/to_hetero_transformer.py:197\u001b[0m, in \u001b[0;36mToHeteroTransformer.call_message_passing_module\u001b[0;34m(self, node, target, name)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_message_passing_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, node: Node, target: Any, name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# Add calls to edge type-wise `MessagePassing` modules and aggregate\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# the outputs to node type-wise embeddings afterwards.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     module \u001b[38;5;241m=\u001b[39m get_submodule(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, target)\n\u001b[0;32m--> 197\u001b[0m     \u001b[43mcheck_add_self_loops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;66;03m# Group edge-wise keys per destination:\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     key_name, keys_per_dst \u001b[38;5;241m=\u001b[39m {}, defaultdict(\u001b[38;5;28mlist\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/BTP/lib/python3.10/site-packages/torch_geometric/utils/hetero.py:55\u001b[0m, in \u001b[0;36mcheck_add_self_loops\u001b[0;34m(module, edge_types)\u001b[0m\n\u001b[1;32m     53\u001b[0m is_bipartite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m([key[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m key[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m edge_types])\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bipartite \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_self_loops\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_self_loops\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m attribute set to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor use with edge type(s) \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. This will lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincorrect message passing results.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: 'add_self_loops' attribute set to 'True' on module 'GATConv((-1, -1), 500, heads=1)' for use with edge type(s) '[('users', 'likes', 'movies'), ('movies', 'rev_likes', 'users')]'. This will lead to incorrect message passing results."
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as nng \n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "class GNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nng.GATConv((-1, -1), hidden_channels)#, train_data.metadata())\n",
    "        self.conv2 = nng.GATConv((-1, -1), hidden_channels)#, train_data.metadata())\n",
    "        self.conv3 = nng.GATConv((-1, -1), out_channels)#, train_data.metadata())\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).sigmoid()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        return x\n",
    "    \n",
    "class EdgeDecoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.lin3 = nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.lin4 = nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['users'][row], z_dict['movies'][col]], dim=-1)\n",
    "        z = self.lin1(z).sigmoid()\n",
    "#         z = self.lin2(z).relu()\n",
    "#         z = self.lin3(z).sigmoid()\n",
    "        z = self.lin4(z).relu()\n",
    "        return z.view(-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
    "        self.encoder = nng.to_hetero(self.encoder, train_data.metadata(), aggr='sum')\n",
    "        self.decoder = EdgeDecoder(hidden_channels)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        x_dict, edge_index_dict, edge_label_index = X.x_dict, X.edge_index_dict, X['users', 'movies'].edge_label_index\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        return self.decoder(z_dict, edge_label_index)\n",
    "    \n",
    "    def train(self, train_data = train_data, epochs = 1000):\n",
    "        self.loss = weighted_mse_loss\n",
    "        self.optim = torch.optim.Adam(self.parameters(), lr = 1e-4)\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        for i in tqdm(range(epochs)):\n",
    "            self.optim.zero_grad()\n",
    "            otpt = self.forward(train_data)\n",
    "            trgt = train_data['users', 'movies'].edge_label.float()\n",
    "            loss, loss_ = self.loss(otpt, trgt)\n",
    "            loss.backward()\n",
    "            self.optim.step()\n",
    "            self.train_loss.append(torch.sqrt(loss_).cpu().detach().numpy())\n",
    "            self.val_loss.append(self.test()[0].cpu())\n",
    "        return(self.train_loss, self.val_loss)\n",
    "            \n",
    "    def test(self, data = test_data):\n",
    "        with torch.no_grad():\n",
    "            otpt_cont = self.forward(data)\n",
    "            print(otpt_cont)\n",
    "            trgt_cont = data['users', 'movies'].edge_label.float()\n",
    "            loss, loss_ = self.loss(otpt_cont, trgt_cont)\n",
    "            trgt = torch.div(trgt_cont, 4, rounding_mode=\"floor\").cpu()\n",
    "            otpt = (otpt_cont > 2.5).float().cpu()\n",
    "            print(classification_report(trgt, otpt, zero_division=0))\n",
    "        return(torch.sqrt(loss_),\n",
    "               precision_score(trgt, otpt, zero_division=0, average='weighted'), \n",
    "               recall_score(trgt, otpt, average='weighted'))\n",
    "\n",
    "model = Model(hidden_channels = 500).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5332038d",
   "metadata": {
    "id": "5332038d",
    "outputId": "67fb6272-aa4f-45f7-9d66-d783d7a1cf28",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = model.train(train_data, epochs= 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13c2fd",
   "metadata": {
    "id": "ad13c2fd"
   },
   "outputs": [],
   "source": [
    "model.test(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984a9c75",
   "metadata": {
    "id": "984a9c75"
   },
   "outputs": [],
   "source": [
    "min(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd7eaf",
   "metadata": {
    "id": "1edd7eaf"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax2 = ax.twinx()\n",
    "ax.plot(output[0][50:], label = \"Train Loss\", color = \"orange\")\n",
    "ax2.plot(output[1][50:], label = \"Test Loss\")\n",
    "fig.legend([ax, ax2], labels = [\"Train Loss\", \"Test Loss\"], loc = \"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c588773",
   "metadata": {
    "id": "2c588773"
   },
   "outputs": [],
   "source": [
    "pred = model(train_data).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d604ab",
   "metadata": {
    "id": "c6d604ab"
   },
   "outputs": [],
   "source": [
    "true = train_data['users', 'movies'].edge_label.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044652fd",
   "metadata": {
    "id": "044652fd"
   },
   "outputs": [],
   "source": [
    "list(zip(pred, true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bacc37",
   "metadata": {
    "id": "b1bacc37"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "GCNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
